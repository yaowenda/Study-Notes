{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e9a906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5f053fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6522a83f758437a9114e2b2b1cca2df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/828 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/jax/_src/cloud_tpu_init.py:86: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c \"echo always > /sys/kernel/mm/transparent_hugepage/enabled\")\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "114a5991de3849cfaa641e85300b2c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/156M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"hfl/rbt3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7834302a",
   "metadata": {},
   "source": [
    "## 模型加载参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aff3ebcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"directionality\": \"bidi\",\n",
       "  \"dtype\": \"float32\",\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 3,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_fc_size\": 768,\n",
       "  \"pooler_num_attention_heads\": 12,\n",
       "  \"pooler_num_fc_layers\": 3,\n",
       "  \"pooler_size_per_head\": 128,\n",
       "  \"pooler_type\": \"first_token_transform\",\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.57.1\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 21128\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20b7e953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"directionality\": \"bidi\",\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 3,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_fc_size\": 768,\n",
       "  \"pooler_num_attention_heads\": 12,\n",
       "  \"pooler_num_fc_layers\": 3,\n",
       "  \"pooler_size_per_head\": 128,\n",
       "  \"pooler_type\": \"first_token_transform\",\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.57.1\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 21128\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\"hfl/rbt3\")\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90b3808b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2483, 2207, 4638, 2769,  738, 3300, 1920, 3457, 2682,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen = \"弱小的我也有大梦想\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hfl/rbt3\")\n",
    "inputs = tokenizer(sen, return_tensors=\"pt\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781e240b",
   "metadata": {},
   "source": [
    "## 不带Model Head的模型调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a87d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.2872,  0.5480,  0.3357,  ..., -0.3296,  0.0717, -0.1080],\n",
       "         [-0.8537, -0.3002,  0.4380,  ...,  0.0510, -0.4261, -0.6406],\n",
       "         [-0.1367,  0.6865,  0.1021,  ..., -0.3336,  0.4131, -0.5922],\n",
       "         ...,\n",
       "         [-0.0061,  0.2498,  0.7738,  ..., -0.1544, -0.4102, -0.4334],\n",
       "         [ 0.1017,  0.5554, -0.3440,  ..., -0.1113,  0.3610,  0.2782],\n",
       "         [ 0.2811,  0.5505,  0.3344,  ..., -0.3255,  0.0713, -0.1040]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 6.4035e-03, -9.9755e-01, -9.9986e-01, -8.0316e-01,  8.9692e-01,\n",
       "         -1.0432e-01,  1.7788e-01, -7.0312e-03,  9.9760e-01,  9.9925e-01,\n",
       "          7.8582e-02, -1.0000e+00,  7.1475e-02,  9.9982e-01, -9.9997e-01,\n",
       "          9.9974e-01,  9.9521e-01,  8.9890e-01, -9.9948e-01, -1.6133e-01,\n",
       "         -9.9497e-01, -9.5804e-01,  1.9115e-01,  9.4259e-01,  9.9322e-01,\n",
       "         -9.9596e-01, -9.9983e-01,  1.7319e-01, -7.7147e-01, -9.9880e-01,\n",
       "         -9.9268e-01, -9.9990e-01,  3.9995e-01, -1.3943e-01,  9.9521e-01,\n",
       "         -9.3905e-01,  7.2548e-02, -9.7846e-01, -9.9851e-01, -9.9838e-01,\n",
       "         -1.5202e-01,  9.9731e-01, -5.9521e-02,  9.9991e-01, -1.3359e-01,\n",
       "         -1.6017e-02,  9.9980e-01,  9.9123e-01, -1.2853e-01, -5.5195e-01,\n",
       "         -2.0149e-01, -3.4785e-01, -9.4770e-01,  9.9801e-01,  2.4326e-01,\n",
       "          7.4711e-02,  9.9947e-01, -9.9999e-01, -9.9857e-01,  9.8921e-01,\n",
       "         -9.9968e-01,  9.9794e-01,  9.9318e-01,  9.9705e-01, -5.4107e-01,\n",
       "          9.9954e-01,  9.9687e-01,  8.8877e-01, -2.0600e-01, -9.9993e-01,\n",
       "         -1.7743e-01, -9.7878e-01, -9.9956e-01,  1.2297e-02, -3.4836e-01,\n",
       "         -9.8459e-01,  9.8367e-01, -2.9358e-01,  9.9975e-01,  2.1279e-02,\n",
       "         -9.9859e-01,  4.1207e-01,  1.8857e-01, -7.7348e-02,  9.9893e-01,\n",
       "          9.9995e-01,  1.0391e-01, -9.7148e-01, -1.5444e-01, -9.9672e-01,\n",
       "         -7.7531e-01,  9.9625e-01,  9.9986e-01, -9.9926e-01,  9.9979e-01,\n",
       "         -9.2728e-01, -2.0981e-01,  2.2036e-01, -9.9169e-01,  8.6767e-01,\n",
       "         -1.1134e-01, -1.5984e-01,  9.9996e-01,  9.5647e-01,  6.4531e-01,\n",
       "         -9.9985e-01, -9.3513e-01,  9.9848e-01, -9.9738e-01,  2.1643e-01,\n",
       "          1.0000e+00,  7.2815e-01,  1.0000e+00,  9.9962e-01,  9.9988e-01,\n",
       "         -9.9956e-01, -2.6390e-01,  2.5399e-01, -9.9972e-01,  9.9051e-01,\n",
       "         -9.9541e-01,  1.8054e-02, -5.3505e-01, -1.8822e-01,  1.2724e-01,\n",
       "         -9.9989e-01,  3.0552e-02,  5.4079e-02, -9.3462e-01, -9.9549e-01,\n",
       "         -9.9568e-01, -9.9994e-01,  9.4312e-01,  9.3547e-01,  2.3147e-03,\n",
       "         -3.4072e-01,  3.7639e-01, -8.2493e-02, -9.9998e-01, -9.9968e-01,\n",
       "         -9.9998e-01,  2.3031e-01, -7.5987e-01,  9.9568e-01, -9.9159e-01,\n",
       "          9.9921e-01, -9.9868e-01,  9.9970e-01,  9.9007e-01, -5.1959e-02,\n",
       "         -7.2912e-01, -4.3809e-02, -9.9803e-01,  9.5514e-02, -1.3134e-01,\n",
       "          9.9200e-01,  9.9453e-01,  4.8311e-01,  4.0066e-01,  9.9999e-01,\n",
       "         -9.9241e-01,  9.1763e-01, -2.4778e-01,  9.8257e-01,  9.9999e-01,\n",
       "         -9.9996e-01,  2.9532e-01, -1.0000e+00,  3.2446e-01,  5.3085e-02,\n",
       "          9.9990e-01,  9.9581e-01,  3.0217e-01,  9.9870e-01, -8.7813e-01,\n",
       "         -9.9986e-01,  6.0570e-01, -9.9989e-01,  9.4877e-01,  9.9999e-01,\n",
       "          5.1429e-03,  6.2710e-01,  9.9999e-01,  4.3758e-01,  9.2621e-01,\n",
       "         -2.0421e-01, -1.3192e-02, -9.9734e-01,  2.3679e-01,  9.2574e-01,\n",
       "          9.8644e-01, -9.5136e-01,  1.3593e-01,  9.9247e-01, -1.1737e-01,\n",
       "         -1.5737e-03, -9.7773e-01, -9.8790e-01,  9.9884e-01,  9.9863e-01,\n",
       "          4.2074e-01, -2.3494e-01,  9.9997e-01, -9.6113e-02,  9.9937e-01,\n",
       "          2.1895e-01,  9.2967e-01, -1.3286e-01,  9.9890e-01,  2.9394e-01,\n",
       "          6.5770e-01, -1.1801e-01,  9.9977e-01, -8.4109e-01, -9.9966e-01,\n",
       "          9.6602e-03, -3.4523e-01,  2.8925e-01, -9.8077e-01,  2.0257e-02,\n",
       "         -3.2455e-01,  9.9989e-01, -4.3774e-03, -9.9237e-01,  9.9567e-01,\n",
       "         -9.9683e-01,  5.3959e-01, -1.0000e+00, -9.9813e-01,  9.9942e-01,\n",
       "         -1.0381e-01, -1.0000e+00,  4.1555e-01,  1.0000e+00, -9.7516e-01,\n",
       "          9.9927e-01, -1.7084e-01, -9.9952e-01,  5.6333e-02, -1.8801e-01,\n",
       "         -9.9999e-01, -9.9846e-01, -9.9999e-01, -8.0412e-01, -3.4799e-02,\n",
       "          9.9635e-01, -9.9999e-01,  2.0428e-01, -9.9984e-01,  9.9540e-01,\n",
       "          9.9997e-01, -1.2071e-01, -3.1928e-01,  9.9999e-01,  2.0434e-04,\n",
       "          5.3872e-02, -1.5780e-01,  1.6927e-01,  1.3876e-01,  9.9650e-01,\n",
       "          5.1671e-01,  9.9938e-01, -9.9892e-01,  2.1051e-01,  6.1181e-01,\n",
       "         -9.9991e-01, -5.0264e-01,  9.7188e-01,  2.0423e-01,  1.4443e-01,\n",
       "         -1.1132e-01,  1.7141e-01,  9.6492e-01,  9.8724e-01,  1.0000e+00,\n",
       "          9.4526e-01,  9.9999e-01,  9.9988e-01, -7.3304e-02, -9.7531e-01,\n",
       "         -3.2997e-01,  1.1705e-01, -9.9987e-01, -9.4290e-01, -9.9896e-01,\n",
       "          9.4976e-01,  2.5216e-01,  1.0000e+00, -9.9992e-01,  9.9998e-01,\n",
       "         -8.7365e-01,  3.1095e-01, -2.7302e-02,  3.0709e-01, -5.7781e-01,\n",
       "         -1.1291e-01,  9.9449e-01, -1.0197e-02,  9.6570e-01,  9.8763e-01,\n",
       "          1.7455e-02, -2.0770e-01,  6.4380e-02, -1.0897e-01,  9.8228e-01,\n",
       "         -9.8685e-01,  9.6680e-01, -7.2639e-02,  9.9875e-01, -2.0139e-01,\n",
       "         -9.9998e-01,  9.9951e-01, -9.9845e-01, -4.5956e-01, -9.9867e-01,\n",
       "         -9.5555e-01, -2.9403e-02, -9.9541e-01,  9.5516e-01,  9.9842e-01,\n",
       "          3.6924e-01,  4.1921e-03, -9.9998e-01, -8.9928e-01,  9.8972e-01,\n",
       "          9.9988e-01, -9.9981e-01,  9.9808e-01,  9.2823e-01, -6.7849e-01,\n",
       "          3.7683e-01,  8.3810e-01, -9.9966e-01,  9.9962e-01, -9.9998e-01,\n",
       "          1.0206e-01,  9.9259e-01, -2.0917e-03, -9.9915e-01, -9.0867e-01,\n",
       "         -1.3796e-01,  3.8873e-01,  7.7536e-05,  9.9981e-01, -2.2709e-01,\n",
       "          2.3356e-02, -9.9985e-01, -9.6874e-01, -5.3760e-01,  2.2028e-01,\n",
       "          9.9873e-01, -9.9999e-01,  8.6798e-01,  9.9919e-01, -9.9888e-01,\n",
       "         -4.0687e-01,  2.9693e-02,  4.5144e-02,  7.0198e-02, -9.8750e-01,\n",
       "         -9.9996e-01, -9.9943e-01,  9.9929e-01, -2.3770e-02, -4.3547e-01,\n",
       "          9.9242e-01,  9.9959e-01,  9.9962e-01, -9.9737e-01,  7.7450e-01,\n",
       "          9.9873e-01, -2.2552e-01,  3.1004e-01, -3.2004e-01, -4.7112e-01,\n",
       "         -8.7713e-01, -9.9224e-01,  2.0248e-01,  6.2341e-01, -4.5587e-02,\n",
       "         -9.7354e-01,  9.9994e-01,  9.9978e-01,  9.9998e-01, -2.5011e-02,\n",
       "         -9.4344e-01,  5.4615e-01, -7.7441e-01, -9.9242e-01,  1.1289e-01,\n",
       "          9.9937e-01, -9.9821e-01,  8.4763e-02,  3.3443e-01, -9.8662e-01,\n",
       "          9.9799e-01, -9.8829e-01,  3.3638e-01, -9.9999e-01, -9.9966e-01,\n",
       "         -9.9999e-01,  9.9997e-01,  1.4715e-01, -1.9964e-01, -9.9027e-01,\n",
       "          9.9999e-01,  9.9619e-01, -8.8897e-01, -3.8836e-01,  9.9971e-01,\n",
       "         -6.2239e-01, -3.1034e-01, -9.9998e-01, -9.9902e-01,  9.9533e-01,\n",
       "          1.7515e-01,  9.9897e-01, -1.6534e-01, -9.8171e-01,  6.8961e-01,\n",
       "          9.6500e-01,  3.2281e-01, -9.8560e-01, -9.9131e-01,  2.1009e-01,\n",
       "          1.9240e-01,  8.6605e-02,  2.5538e-01, -1.4008e-01,  9.9915e-01,\n",
       "          1.0142e-01, -1.2847e-01, -1.8334e-01,  9.9998e-01,  4.8917e-01,\n",
       "         -9.9280e-01, -8.9809e-01, -5.6341e-02, -9.7927e-01, -9.9910e-01,\n",
       "         -9.9974e-01, -8.2052e-02,  1.7630e-01,  1.5101e-01, -9.5371e-01,\n",
       "         -9.9981e-01, -9.9957e-01,  7.5620e-02, -9.7476e-01, -9.7664e-01,\n",
       "          8.5220e-02, -9.9937e-01, -9.7199e-01,  9.9879e-01, -9.9960e-01,\n",
       "         -5.9048e-02,  9.8036e-01,  9.7350e-01, -9.9982e-01,  3.9533e-02,\n",
       "          9.9148e-01, -9.9429e-01,  2.8157e-01, -9.4261e-01,  2.6020e-02,\n",
       "         -8.4316e-01, -9.9999e-01, -3.8734e-02,  9.9968e-01,  9.9904e-01,\n",
       "          9.9679e-01,  9.2691e-01, -7.4987e-01,  9.5879e-01,  9.9891e-01,\n",
       "          9.9996e-01,  1.0658e-01, -9.6297e-02, -9.9998e-01,  4.0660e-02,\n",
       "          7.5449e-01,  2.4874e-01,  4.7700e-01, -9.9958e-01,  2.1823e-01,\n",
       "         -5.4297e-01,  2.1834e-01,  1.0000e+00,  9.8453e-01, -5.9783e-01,\n",
       "         -1.0000e+00, -5.6410e-02, -1.6553e-01,  4.0642e-02, -9.8311e-01,\n",
       "          1.5215e-01,  9.9994e-01, -9.8628e-01,  6.7941e-03, -9.9900e-01,\n",
       "         -9.9915e-01,  9.9991e-01, -9.9994e-01,  9.9989e-01,  7.7646e-01,\n",
       "         -8.6556e-01, -1.7513e-01, -6.9473e-01, -2.6038e-02,  1.6773e-02,\n",
       "         -1.3433e-01, -4.1106e-02, -6.4921e-02, -9.9997e-01, -9.4882e-02,\n",
       "          9.9614e-01, -8.8772e-02, -9.2568e-01, -9.9625e-01,  1.8569e-01,\n",
       "          9.9061e-01, -9.9945e-01, -9.9904e-01, -9.3660e-02, -3.6755e-01,\n",
       "          3.0628e-01, -2.0948e-02, -1.1280e-01, -1.7880e-01, -9.4352e-01,\n",
       "          7.3756e-02,  9.7632e-01, -9.3477e-01,  8.6384e-01, -9.2232e-01,\n",
       "         -9.2302e-01, -2.1148e-01,  9.9962e-01,  9.9816e-01, -9.9971e-01,\n",
       "         -9.9980e-01, -2.3518e-01, -6.2668e-02, -6.2596e-01,  9.9757e-01,\n",
       "         -5.9005e-02, -9.9522e-01,  1.4160e-03,  2.0158e-01, -3.0886e-01,\n",
       "         -7.6915e-01,  9.9996e-01, -9.9559e-01,  9.9999e-01, -1.0000e+00,\n",
       "         -8.4356e-01, -8.2180e-02,  9.9986e-01, -9.9983e-01, -3.8149e-01,\n",
       "          9.9780e-01, -9.9998e-01, -5.9177e-02, -7.8417e-01,  4.1600e-01,\n",
       "         -1.0631e-01,  1.7973e-02,  7.7475e-01, -9.9907e-01,  1.8179e-01,\n",
       "         -9.9892e-01,  6.9503e-01,  9.5638e-01, -9.9982e-01, -1.2548e-01,\n",
       "         -9.9999e-01, -6.1757e-02,  1.1680e-01, -9.9980e-01,  9.9561e-01,\n",
       "          9.9990e-01, -6.6897e-02,  8.9669e-01, -9.9944e-01,  2.0709e-02,\n",
       "         -2.2394e-01, -9.9545e-01,  2.8825e-02, -9.9980e-01,  2.3977e-01,\n",
       "         -9.8951e-01,  9.6125e-01, -9.9991e-01,  9.7833e-01,  9.9479e-01,\n",
       "         -1.5931e-01, -6.0413e-01, -9.2235e-03, -7.3518e-01, -9.9991e-01,\n",
       "          4.6623e-01, -9.9886e-01, -9.9814e-01,  1.4875e-01,  9.9875e-01,\n",
       "          9.8788e-01,  3.3524e-01,  9.9075e-01, -9.9601e-01, -2.3096e-02,\n",
       "          3.7230e-01,  5.2568e-01,  1.0000e+00, -9.9925e-01, -9.9807e-01,\n",
       "          9.9272e-01, -9.9963e-01, -9.7230e-01,  1.0000e+00, -8.2930e-01,\n",
       "          9.9983e-01, -5.5600e-03, -9.9788e-01, -8.4652e-02,  1.8140e-01,\n",
       "          9.9762e-01, -1.1960e-01, -1.1419e-01,  9.8358e-01, -1.6554e-01,\n",
       "         -7.8976e-02, -8.3522e-01,  9.2459e-01, -8.0156e-02, -9.9810e-02,\n",
       "          9.8857e-01, -9.8363e-01, -9.9942e-01, -9.9923e-01,  1.0777e-01,\n",
       "         -1.9100e-01, -2.3384e-01, -2.6322e-02,  8.2309e-01,  9.9916e-01,\n",
       "         -9.9732e-01,  9.9467e-01, -1.0000e+00, -9.9992e-01,  1.2777e-01,\n",
       "          1.1475e-01,  9.9630e-01, -1.4060e-02, -8.2535e-01,  6.7548e-02,\n",
       "         -9.9594e-01,  9.8739e-01, -9.9669e-01,  9.7950e-01, -8.2848e-02,\n",
       "          1.9872e-01,  9.9985e-01,  9.9900e-01, -3.0217e-02, -9.9742e-01,\n",
       "         -9.7711e-01,  1.9997e-02, -9.9245e-01,  9.9866e-01,  7.4339e-02,\n",
       "         -3.8296e-02,  5.4497e-03, -2.2875e-01, -9.9874e-01, -9.9353e-01,\n",
       "          2.0962e-01,  9.9426e-01, -9.9961e-01,  9.8877e-01, -9.8851e-01,\n",
       "          9.9801e-01,  9.9786e-01,  1.0000e+00, -6.7063e-02,  9.8301e-01,\n",
       "         -9.9905e-01, -9.8368e-01,  9.9088e-01,  9.7515e-01,  1.0000e+00,\n",
       "          9.8509e-01,  6.1795e-01,  2.3160e-01, -9.9998e-01,  9.8078e-01,\n",
       "         -1.8623e-01, -3.5184e-02,  1.1035e-01, -9.6246e-01, -9.9987e-01,\n",
       "          9.9997e-01, -9.9998e-01, -9.9991e-01, -8.9885e-01, -9.9953e-01,\n",
       "          9.9759e-01,  9.4572e-01,  9.9959e-01,  5.0992e-01, -9.9973e-01,\n",
       "         -9.9564e-01,  4.6033e-02, -9.7630e-01, -9.5776e-01, -1.2119e-01,\n",
       "         -9.9999e-01,  1.0557e-01, -1.9089e-03, -9.3716e-01,  4.9291e-01,\n",
       "         -9.5767e-01,  8.7755e-01,  8.6827e-01, -3.6812e-01,  9.6844e-01,\n",
       "         -9.8002e-01, -9.9513e-01,  1.0573e-01, -9.9999e-01,  9.6458e-01,\n",
       "          9.9987e-01, -6.8448e-02,  5.5168e-01, -9.5539e-01,  6.4894e-02,\n",
       "         -9.9999e-01, -1.0000e+00,  9.7611e-01,  9.9985e-01,  3.6185e-01,\n",
       "         -9.9834e-01,  1.2734e-01, -9.9933e-01, -3.3697e-02,  9.3768e-01,\n",
       "          9.9616e-01, -9.9987e-01,  9.9619e-01, -9.4173e-01,  1.5225e-01,\n",
       "          9.9367e-01, -1.0000e+00,  8.6453e-01, -9.9696e-01,  9.9982e-01,\n",
       "         -1.0000e+00,  9.9963e-01, -3.6686e-01,  6.9667e-03, -1.0180e-01,\n",
       "          9.3196e-01, -9.9980e-01, -2.7627e-01,  9.8342e-01,  9.7184e-01,\n",
       "         -3.1422e-02,  9.9694e-01,  1.3999e-01]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=(tensor([[[[5.0279e-01, 3.8978e-04, 1.7019e-04,  ..., 2.0786e-04,\n",
       "           1.4967e-04, 4.9400e-01],\n",
       "          [5.6476e-03, 9.7464e-02, 1.1701e-01,  ..., 1.6715e-01,\n",
       "           1.8886e-01, 3.9977e-03],\n",
       "          [2.1258e-02, 1.1859e-01, 2.1128e-01,  ..., 1.0566e-01,\n",
       "           1.3053e-01, 3.5442e-03],\n",
       "          ...,\n",
       "          [2.8902e-02, 1.9623e-01, 7.2965e-02,  ..., 2.8762e-01,\n",
       "           1.3522e-01, 5.6913e-03],\n",
       "          [3.3313e-02, 1.0393e-01, 5.4076e-02,  ..., 1.8377e-01,\n",
       "           1.2967e-01, 1.2370e-02],\n",
       "          [5.2037e-01, 9.3542e-04, 4.5754e-04,  ..., 3.8420e-04,\n",
       "           2.7222e-04, 4.7473e-01]],\n",
       "\n",
       "         [[9.9046e-01, 2.5787e-05, 2.0245e-04,  ..., 1.0926e-04,\n",
       "           5.2086e-05, 4.2719e-03],\n",
       "          [1.7754e-02, 1.2910e-04, 9.8203e-01,  ..., 7.6153e-09,\n",
       "           2.9790e-10, 6.0842e-05],\n",
       "          [2.1833e-02, 9.7454e-01, 1.5328e-04,  ..., 1.2092e-07,\n",
       "           1.2470e-08, 1.5003e-06],\n",
       "          ...,\n",
       "          [2.5504e-02, 2.6222e-08, 1.2531e-06,  ..., 2.3459e-05,\n",
       "           9.6880e-01, 4.8542e-04],\n",
       "          [1.1375e-02, 2.9667e-09, 4.1039e-08,  ..., 9.7348e-01,\n",
       "           1.4833e-04, 1.4896e-02],\n",
       "          [9.8323e-01, 2.1659e-05, 2.8234e-06,  ..., 1.2605e-04,\n",
       "           9.1490e-03, 4.6391e-03]],\n",
       "\n",
       "         [[1.7352e-01, 9.5928e-02, 2.7075e-02,  ..., 3.5289e-02,\n",
       "           5.9902e-02, 2.9318e-01],\n",
       "          [4.8443e-01, 3.3012e-01, 3.1873e-02,  ..., 7.3365e-03,\n",
       "           9.1925e-03, 8.7510e-02],\n",
       "          [4.9458e-01, 1.7929e-01, 1.9429e-01,  ..., 3.7944e-03,\n",
       "           4.8320e-03, 6.5862e-02],\n",
       "          ...,\n",
       "          [1.6611e-01, 7.1346e-02, 4.3125e-02,  ..., 1.0680e-01,\n",
       "           1.6288e-02, 5.3834e-02],\n",
       "          [1.5559e-01, 6.1323e-02, 5.8198e-02,  ..., 6.7505e-02,\n",
       "           6.8684e-02, 5.8333e-02],\n",
       "          [4.3903e-02, 5.8588e-02, 5.0134e-02,  ..., 1.0649e-01,\n",
       "           4.7136e-02, 1.4583e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[7.1424e-01, 2.2219e-02, 4.1034e-02,  ..., 2.1423e-02,\n",
       "           2.3981e-02, 8.4501e-02],\n",
       "          [4.1085e-01, 3.2558e-01, 1.1214e-02,  ..., 1.6220e-02,\n",
       "           1.2585e-02, 1.0971e-01],\n",
       "          [6.2266e-01, 5.9040e-03, 5.7687e-03,  ..., 2.1395e-02,\n",
       "           1.8391e-02, 2.4969e-01],\n",
       "          ...,\n",
       "          [6.1235e-01, 3.6581e-03, 2.7701e-02,  ..., 2.5592e-01,\n",
       "           2.2346e-02, 2.3408e-02],\n",
       "          [3.7634e-01, 4.4535e-02, 4.9533e-02,  ..., 8.0901e-02,\n",
       "           2.4642e-01, 8.4861e-02],\n",
       "          [4.3236e-01, 5.9088e-02, 8.5959e-02,  ..., 1.4764e-02,\n",
       "           1.3251e-02, 1.6888e-01]],\n",
       "\n",
       "         [[9.7645e-01, 5.4296e-03, 3.0934e-03,  ..., 1.5397e-03,\n",
       "           1.6835e-03, 4.7978e-03],\n",
       "          [7.9955e-03, 7.2973e-02, 4.8285e-01,  ..., 1.5941e-03,\n",
       "           4.2028e-03, 4.4792e-03],\n",
       "          [1.4907e-03, 7.1796e-03, 1.7603e-02,  ..., 3.6566e-04,\n",
       "           6.1814e-04, 9.8165e-03],\n",
       "          ...,\n",
       "          [6.1862e-03, 1.6512e-03, 2.8931e-03,  ..., 3.1646e-02,\n",
       "           3.4554e-01, 5.9431e-01],\n",
       "          [1.5513e-03, 4.4795e-04, 1.6513e-04,  ..., 1.5977e-03,\n",
       "           5.5347e-03, 9.8674e-01],\n",
       "          [9.9462e-01, 3.1062e-04, 1.2542e-04,  ..., 1.3359e-04,\n",
       "           2.9041e-04, 4.3195e-03]],\n",
       "\n",
       "         [[4.4257e-01, 2.5473e-02, 2.0564e-02,  ..., 1.9800e-02,\n",
       "           1.6701e-02, 3.2930e-01],\n",
       "          [7.5506e-01, 1.1013e-01, 2.2809e-03,  ..., 2.7339e-02,\n",
       "           4.7737e-03, 2.3195e-02],\n",
       "          [4.4037e-02, 9.3259e-01, 6.5302e-03,  ..., 9.6156e-04,\n",
       "           1.7772e-04, 1.0292e-03],\n",
       "          ...,\n",
       "          [1.9903e-01, 8.3400e-03, 4.5036e-04,  ..., 2.7681e-02,\n",
       "           1.1747e-02, 2.8712e-02],\n",
       "          [4.3934e-02, 1.1345e-03, 7.7104e-05,  ..., 8.9882e-01,\n",
       "           2.7849e-02, 7.7160e-03],\n",
       "          [8.9495e-02, 3.2219e-03, 4.0571e-03,  ..., 3.7143e-02,\n",
       "           1.6588e-01, 6.8151e-01]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[4.5216e-01, 1.3392e-02, 6.4814e-03,  ..., 1.5072e-02,\n",
       "           1.5373e-02, 4.3405e-01],\n",
       "          [4.8097e-01, 9.5247e-03, 2.4852e-03,  ..., 8.6056e-05,\n",
       "           5.8842e-06, 5.0004e-01],\n",
       "          [1.7034e-02, 9.6630e-01, 1.1340e-05,  ..., 6.8685e-06,\n",
       "           8.4202e-07, 1.5721e-02],\n",
       "          ...,\n",
       "          [2.5174e-01, 7.3831e-04, 1.1394e-05,  ..., 2.3024e-03,\n",
       "           1.8252e-03, 2.3209e-01],\n",
       "          [7.6087e-02, 3.0374e-05, 1.3250e-05,  ..., 8.4381e-01,\n",
       "           4.9619e-05, 7.7236e-02],\n",
       "          [4.5415e-01, 1.3157e-02, 6.2322e-03,  ..., 1.3997e-02,\n",
       "           1.6423e-02, 4.3565e-01]],\n",
       "\n",
       "         [[4.6492e-01, 1.0483e-02, 7.0382e-03,  ..., 1.0396e-02,\n",
       "           6.8207e-03, 4.5264e-01],\n",
       "          [3.2382e-01, 1.6420e-02, 1.2498e-02,  ..., 5.4662e-02,\n",
       "           5.1684e-02, 3.2519e-01],\n",
       "          [2.6507e-01, 2.5219e-02, 9.1247e-03,  ..., 8.3089e-02,\n",
       "           9.6201e-02, 2.6474e-01],\n",
       "          ...,\n",
       "          [4.0789e-01, 1.5870e-02, 7.7997e-03,  ..., 1.8541e-02,\n",
       "           4.3365e-02, 4.0949e-01],\n",
       "          [2.6974e-01, 4.1414e-02, 1.9938e-02,  ..., 5.7939e-02,\n",
       "           1.2795e-01, 2.6988e-01],\n",
       "          [4.6706e-01, 9.7240e-03, 6.5964e-03,  ..., 9.9338e-03,\n",
       "           6.4399e-03, 4.5504e-01]],\n",
       "\n",
       "         [[4.9367e-01, 4.8892e-03, 3.7466e-03,  ..., 5.7458e-03,\n",
       "           2.7383e-03, 4.5038e-01],\n",
       "          [4.1554e-01, 1.8295e-01, 8.7656e-03,  ..., 2.1115e-03,\n",
       "           2.7120e-03, 3.7954e-01],\n",
       "          [3.8562e-01, 1.3371e-01, 9.4296e-02,  ..., 1.9019e-03,\n",
       "           2.5268e-03, 3.5349e-01],\n",
       "          ...,\n",
       "          [3.2827e-01, 1.9767e-03, 4.3831e-04,  ..., 3.3807e-01,\n",
       "           1.8427e-02, 3.0683e-01],\n",
       "          [3.5595e-01, 4.5656e-03, 4.4502e-04,  ..., 2.6352e-01,\n",
       "           3.8677e-02, 3.3252e-01],\n",
       "          [4.9362e-01, 5.0598e-03, 3.8117e-03,  ..., 6.1379e-03,\n",
       "           2.8721e-03, 4.4980e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[4.5000e-01, 1.0465e-02, 2.1336e-02,  ..., 1.3263e-02,\n",
       "           2.6858e-02, 4.2569e-01],\n",
       "          [2.7652e-01, 1.5180e-02, 2.7893e-02,  ..., 4.0836e-02,\n",
       "           2.6275e-02, 2.8147e-01],\n",
       "          [2.6762e-01, 7.7614e-03, 1.2152e-02,  ..., 9.4175e-02,\n",
       "           2.4965e-02, 2.7460e-01],\n",
       "          ...,\n",
       "          [4.1765e-01, 1.0525e-02, 5.2121e-03,  ..., 5.0393e-02,\n",
       "           6.7757e-02, 4.2549e-01],\n",
       "          [4.2012e-01, 2.2974e-02, 3.4980e-02,  ..., 2.0741e-02,\n",
       "           2.9210e-02, 4.1974e-01],\n",
       "          [4.5170e-01, 9.9885e-03, 2.0364e-02,  ..., 1.2651e-02,\n",
       "           2.5928e-02, 4.2770e-01]],\n",
       "\n",
       "         [[4.8475e-01, 5.0873e-03, 2.5402e-03,  ..., 7.9355e-03,\n",
       "           4.7586e-03, 4.5618e-01],\n",
       "          [4.3660e-01, 1.8473e-02, 1.2353e-02,  ..., 1.3150e-02,\n",
       "           7.9103e-03, 4.3344e-01],\n",
       "          [3.3466e-01, 4.2188e-02, 2.5240e-02,  ..., 3.0504e-02,\n",
       "           2.5034e-02, 3.2349e-01],\n",
       "          ...,\n",
       "          [2.0922e-01, 7.5960e-02, 4.8082e-02,  ..., 3.2619e-02,\n",
       "           3.4031e-02, 2.0435e-01],\n",
       "          [2.3162e-01, 4.9847e-02, 4.2745e-02,  ..., 3.2576e-02,\n",
       "           3.7358e-02, 2.3367e-01],\n",
       "          [4.8450e-01, 5.1518e-03, 2.5519e-03,  ..., 7.8749e-03,\n",
       "           4.6850e-03, 4.5637e-01]],\n",
       "\n",
       "         [[4.7354e-01, 6.5553e-03, 1.4881e-02,  ..., 1.1544e-02,\n",
       "           2.0473e-03, 4.5805e-01],\n",
       "          [2.7431e-01, 6.7808e-02, 4.6166e-02,  ..., 1.4676e-01,\n",
       "           9.2396e-02, 2.6603e-01],\n",
       "          [3.3977e-01, 1.0820e-01, 3.8284e-02,  ..., 2.5852e-02,\n",
       "           2.5449e-02, 3.2849e-01],\n",
       "          ...,\n",
       "          [3.4334e-01, 1.0387e-01, 1.1748e-02,  ..., 4.2701e-02,\n",
       "           5.1978e-02, 3.3207e-01],\n",
       "          [3.0855e-01, 1.5899e-01, 1.4752e-02,  ..., 5.0982e-02,\n",
       "           2.4483e-02, 3.0611e-01],\n",
       "          [4.7377e-01, 6.3268e-03, 1.4662e-02,  ..., 1.1597e-02,\n",
       "           1.9991e-03, 4.5849e-01]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[4.0220e-01, 1.8373e-02, 2.9588e-02,  ..., 1.2729e-02,\n",
       "           2.7237e-02, 3.9577e-01],\n",
       "          [4.7031e-01, 2.3618e-02, 1.7399e-02,  ..., 2.8008e-03,\n",
       "           3.8088e-03, 4.6340e-01],\n",
       "          [4.8692e-01, 1.1768e-02, 8.6011e-03,  ..., 8.1445e-04,\n",
       "           2.7920e-03, 4.7800e-01],\n",
       "          ...,\n",
       "          [2.9166e-01, 3.0290e-02, 2.9290e-02,  ..., 1.3763e-02,\n",
       "           1.1588e-02, 2.8701e-01],\n",
       "          [2.9630e-01, 2.9794e-02, 1.9303e-02,  ..., 1.7765e-02,\n",
       "           1.4833e-02, 2.9143e-01],\n",
       "          [4.0281e-01, 1.8292e-02, 2.9441e-02,  ..., 1.2720e-02,\n",
       "           2.7197e-02, 3.9638e-01]],\n",
       "\n",
       "         [[1.6564e-02, 5.9830e-02, 2.8971e-02,  ..., 5.5419e-02,\n",
       "           2.6486e-01, 1.6475e-02],\n",
       "          [3.2037e-01, 7.0159e-02, 2.3511e-01,  ..., 2.8140e-03,\n",
       "           7.2121e-03, 3.1685e-01],\n",
       "          [9.8836e-02, 7.9045e-01, 3.9816e-03,  ..., 6.7893e-04,\n",
       "           1.8497e-04, 9.7891e-02],\n",
       "          ...,\n",
       "          [2.3237e-01, 9.5339e-03, 1.0507e-02,  ..., 1.2872e-02,\n",
       "           4.6095e-01, 2.2942e-01],\n",
       "          [4.1288e-01, 1.2226e-02, 2.2166e-03,  ..., 1.2483e-01,\n",
       "           1.5562e-02, 4.1146e-01],\n",
       "          [1.6616e-02, 6.0324e-02, 2.8980e-02,  ..., 5.5576e-02,\n",
       "           2.6570e-01, 1.6527e-02]],\n",
       "\n",
       "         [[4.8357e-01, 2.0853e-03, 9.8556e-04,  ..., 8.0572e-04,\n",
       "           4.8740e-03, 4.7851e-01],\n",
       "          [4.4730e-01, 2.9709e-02, 3.2480e-02,  ..., 2.8614e-02,\n",
       "           4.7931e-03, 4.3871e-01],\n",
       "          [4.4481e-01, 1.7397e-02, 4.8983e-02,  ..., 1.5238e-02,\n",
       "           1.5857e-02, 4.3699e-01],\n",
       "          ...,\n",
       "          [4.5979e-01, 9.0756e-03, 3.8861e-03,  ..., 4.4429e-02,\n",
       "           1.6814e-02, 4.5287e-01],\n",
       "          [4.3194e-01, 7.2273e-03, 1.7956e-02,  ..., 3.3522e-02,\n",
       "           6.5240e-02, 4.2506e-01],\n",
       "          [4.8352e-01, 2.1120e-03, 9.8815e-04,  ..., 8.1746e-04,\n",
       "           4.9052e-03, 4.7846e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[3.4182e-02, 9.3989e-02, 7.0065e-02,  ..., 8.4329e-02,\n",
       "           1.8032e-01, 3.3832e-02],\n",
       "          [3.7962e-01, 2.4817e-02, 3.0292e-02,  ..., 1.7683e-02,\n",
       "           1.3347e-02, 3.7618e-01],\n",
       "          [3.8695e-01, 3.0727e-02, 1.3480e-02,  ..., 1.7201e-02,\n",
       "           8.8852e-03, 3.8219e-01],\n",
       "          ...,\n",
       "          [4.6740e-01, 2.6213e-03, 1.7375e-03,  ..., 1.7642e-02,\n",
       "           2.7489e-02, 4.6442e-01],\n",
       "          [4.9020e-01, 2.0731e-03, 9.5278e-04,  ..., 7.5612e-03,\n",
       "           4.7257e-03, 4.8634e-01],\n",
       "          [3.4443e-02, 9.4302e-02, 7.0329e-02,  ..., 8.4090e-02,\n",
       "           1.7950e-01, 3.4091e-02]],\n",
       "\n",
       "         [[3.1751e-02, 2.0084e-02, 4.4512e-02,  ..., 1.0525e-01,\n",
       "           4.7893e-01, 3.1525e-02],\n",
       "          [4.9131e-01, 1.2635e-02, 4.9961e-03,  ..., 4.2056e-04,\n",
       "           5.6530e-04, 4.8598e-01],\n",
       "          [4.6514e-01, 3.9831e-02, 2.5239e-02,  ..., 7.4453e-04,\n",
       "           8.7833e-04, 4.5980e-01],\n",
       "          ...,\n",
       "          [2.6465e-01, 4.1215e-03, 4.4306e-03,  ..., 1.4379e-02,\n",
       "           1.2806e-02, 2.5933e-01],\n",
       "          [1.2625e-01, 7.1403e-03, 5.2366e-03,  ..., 2.2585e-02,\n",
       "           1.8709e-02, 1.2368e-01],\n",
       "          [3.1692e-02, 1.9934e-02, 4.4195e-02,  ..., 1.0570e-01,\n",
       "           4.8084e-01, 3.1467e-02]],\n",
       "\n",
       "         [[1.9683e-01, 3.6389e-02, 3.2817e-02,  ..., 6.1556e-02,\n",
       "           1.3962e-01, 1.9296e-01],\n",
       "          [3.6979e-01, 7.2091e-03, 1.0162e-01,  ..., 7.5631e-03,\n",
       "           6.1427e-03, 3.6660e-01],\n",
       "          [4.0221e-01, 3.6293e-03, 5.5452e-03,  ..., 4.5846e-04,\n",
       "           6.4430e-04, 3.9908e-01],\n",
       "          ...,\n",
       "          [4.4382e-01, 6.2984e-04, 2.3532e-03,  ..., 2.0332e-02,\n",
       "           7.0646e-02, 4.4340e-01],\n",
       "          [4.9460e-01, 7.6055e-04, 5.9136e-04,  ..., 1.4127e-03,\n",
       "           2.8891e-03, 4.9555e-01],\n",
       "          [1.9784e-01, 3.6595e-02, 3.2688e-02,  ..., 6.1153e-02,\n",
       "           1.3859e-01, 1.9395e-01]]]], grad_fn=<SoftmaxBackward0>)), cross_attentions=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"hfl/rbt3\", output_attentions=True) # 不加output_attentions=True，并不返回attention\n",
    "# 简单来说就是可以配置一些运行参数，让模型在进行运行的时候得到变化\n",
    "outputs = model(**inputs)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f4dd28",
   "metadata": {},
   "source": [
    "因为这里使用的是不带model head的模型，所以模型最后的输出就是输入编码，就是上面输出的last_hidden_state，可以通过这种方式取出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c716eaa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2872,  0.5480,  0.3357,  ..., -0.3296,  0.0717, -0.1080],\n",
       "         [-0.8537, -0.3002,  0.4380,  ...,  0.0510, -0.4261, -0.6406],\n",
       "         [-0.1367,  0.6865,  0.1021,  ..., -0.3336,  0.4131, -0.5922],\n",
       "         ...,\n",
       "         [-0.0061,  0.2498,  0.7738,  ..., -0.1544, -0.4102, -0.4334],\n",
       "         [ 0.1017,  0.5554, -0.3440,  ..., -0.1113,  0.3610,  0.2782],\n",
       "         [ 0.2811,  0.5505,  0.3344,  ..., -0.3255,  0.0713, -0.1040]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67d8331e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11, 768])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b997f92c",
   "metadata": {},
   "source": [
    "## 带Model Head的模型调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cf5dfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec3da4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/rbt3 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "clz_model = AutoModelForSequenceClassification.from_pretrained(\"hfl/rbt3\", num_labels=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aea37ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-0.2164, -0.3057]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clz_model(**inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b194e85d",
   "metadata": {},
   "source": [
    "## 手写实现文本分类示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d72fa53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76406a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是否在 Colab 环境中？\n",
      "✓ 是 Colab 环境\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"是否在 Colab 环境中？\")\n",
    "try:\n",
    "  import google.colab\n",
    "  print(\"✓ 是 Colab 环境\")\n",
    "except ImportError:\n",
    "  print(\"✗ 不是 Colab 环境！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b30dd26",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1286092f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './ChnSentiCorp_htl_all.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1082748427.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./ChnSentiCorp_htl_all.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './ChnSentiCorp_htl_all.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"/content/drive/MyDrive/data/ChnSentiCorp_htl_all.csv\")\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
